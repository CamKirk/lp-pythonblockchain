{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'markov'"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "\"markov\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the string into bytes. This doesn't render with a massive change in python other than the \"b\" being added to the front."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "b'markov'"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "bytes(\"markov\", \"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can unpack the bytes for each metter in the word `markov` by using a loop. Then, we can _hash_ the entire word's bytes to see that the `hashing function` converts the bytes into something... well different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "109\n97\n114\n107\n111\n118\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'43cedaa98924112f2f89c3277a0c1f7ecc487350c22d428ebd2f61dc32389787'"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "for letter in bytes(\"markov\", \"utf-8\"):\n",
    "    print(letter)\n",
    "m = hashlib.sha256()\n",
    "m.update(bytes(\"markov\", \"utf-8\"))\n",
    "m.hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we make the small, subtle change of one letter in `markov` to `markon`, we can see the bytes don't change very much. However, the hash is _dramatically_ different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "109\n97\n114\n107\n111\n110\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'d9a3984bfb9ffb3d8287bee1398821f4adfe09f7f9daf80d56e5006f6e6ab866'"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "for letter in bytes(\"markon\", \"utf-8\"):\n",
    "    print(letter)\n",
    "m = hashlib.sha256()\n",
    "m.update(bytes(\"markon\", \"utf-8\"))\n",
    "m.hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each position in the hash can be any of 10 numbers or 26 lower-case letters for a total of 36 possibilities. There are 64 characters in the resultant hash, so the total number of possible characters would be 36^64 combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'4011991914547630480065053387702443812690402487741812225955731622655455723258857248542161222254985216 possible combinations of 64 characters of 36 options'"
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "f\"{(26+10)**64} possible combinations of 64 characters of 36 options\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "moving on, we can again see that the one-letter difference is has a dramatic difference in the hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "43cedaa98924112f2f89c3277a0c1f7ecc487350c22d428ebd2f61dc32389787\nd9a3984bfb9ffb3d8287bee1398821f4adfe09f7f9daf80d56e5006f6e6ab866\n"
    }
   ],
   "source": [
    "a = hashlib.sha256()\n",
    "a.update(bytes(\"markov\", \"utf-8\"))\n",
    "print(a.hexdigest())\n",
    "b = hashlib.sha256()\n",
    "b.update(bytes(\"markon\", \"utf-8\"))\n",
    "print(b.hexdigest())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we did the updates back-to-back?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'2cff5a6595c2c90cafb14a83398e52a161374c4f47496cf09abe53b83acd04b6'"
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "c = hashlib.sha256()\n",
    "c.update(bytes(\"markov\", \"utf-8\"))\n",
    "c.update(bytes(\"markon\", \"utf-8\"))\n",
    "c.hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is different than either of the previous hashes. Running .update() sequentially essentially hashes the two bytes objects together. Below is an example that has the same result, by using addition of the bytes as opposed to multiple updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'2cff5a6595c2c90cafb14a83398e52a161374c4f47496cf09abe53b83acd04b6'"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "d = hashlib.sha256()\n",
    "d.update(bytes(\"markov\", \"utf-8\")+bytes(\"markon\", \"utf-8\"))\n",
    "d.hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the order that the bytes object matter? YES. QUITE A BIT!! (notice that the hash again is dramatically different than the previous value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'0e6bae302ba74bdfb42162b34f17bf1d19bf2bdab50621d3a85084018cb4453e'"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "e = hashlib.sha256()\n",
    "e.update(bytes(\"markon\", \"utf-8\")+bytes(\"markov\", \"utf-8\"))\n",
    "e.hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's consider a situation in which we have a ledger of transactions, like the one below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ledger_block = \"\"\"\n",
    "Akanksha pays Jose 200\n",
    "Jose pays Chase 100\n",
    "Jose pays Aimon 40\n",
    "Jose pays Theo 40\n",
    "Salma pays Shazia 30\n",
    "Aimon pays Jessica 500\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could hash each line of this ledger together into one larger hash using a for-loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'05971ec9f83ba4cbac6325d667d192f6349a8d6154d797576b6d02bdb086baa2'"
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "f = hashlib.sha256()\n",
    "for line in ledger_block.split(\"\\n\"):\n",
    "    f.update(bytes(line,\"utf-8\"))\n",
    "f.hexdigest()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which gives us a hash that can be created only by having _exactly_ those transactions in _exactly_ that order. Even a small change that would be difficult to detect by human eyes makes the hash different, and can act as a fraud-resistant mechanism. For example, the `scam_block` ledger below has a tiny addition made to the original ledger; can you spot the difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scam_block = \"\"\"\n",
    "Akanksha pays Jose 200\n",
    "Jose pays Chase 100\n",
    "Jose pays Aimon 4000\n",
    "Jose pays Theo 40\n",
    "Salma pays Shazia 30\n",
    "Aimon pays Jessica 500\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jose is now baying Aimon $4000 instead of 40. Let's see what happens when we hash the ledger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'712ac912e61300edba3bbb3b148e0cbb84d161ce990ffab6cea00794f1962a85'"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "e = hashlib.sha256()\n",
    "for line in scam_block.split(\"\\n\"):\n",
    "    e.update(bytes(line,\"utf-8\"))\n",
    "e.hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the hash is _very_ different than the last one, and thus we could conclude that some modification to the ledger has been made. Although though we don't know _what the change is_, it's immediately apparent that something has changed and should thus be inspected. This is a great way to check extremely large datasets for differences or changes over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's consider the situation in which we have a ledger that is composed of many pages, which we'll nickname \"blocks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_1 = \"\"\"\n",
    "Akanksha pays Sam 30\n",
    "Sam pays Chase 91\n",
    "Sam pays Aimon 40\n",
    "Sam pays Theo 19\n",
    "Salma pays Shannon 23\n",
    "Aimon pays Margret 89\"\"\"\n",
    "\n",
    "block_2 = \"\"\"\n",
    "Bohr pays Boltzmann 8\n",
    "Boltzmann pays Gibbs 19\n",
    "Hemholtz pays Fuller 12\n",
    "Hemholtz pays Lavoisier 94\n",
    "Fuller pays Bohr 17\n",
    "Lavoisier pays Carnot 91\"\"\"\n",
    "\n",
    "block_3 = \"\"\"\n",
    "Euclid pays Ramanujan 55\n",
    "Descartes pays Euler 34\n",
    "Descartes pays Euler 12\n",
    "Gauss pays Turing 314\n",
    "Pascal pays Gauss 218\n",
    "Gauss pays Pascal 70\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could take each of those blocks, and hash them as a single giant line. However, to do something even more interesting, we can take the current hash, tack on the next set of bytes, and hash them together. That way, the only way to reproduce each successive block is to have _exactly_ the previous block, and _exactly_ the one before that, so on and so forth. This process of chaining the hashes together is referred to as a `blockchain`! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['2c64a519378828ad696519c3b4bc015db11cc8331deb6ec121d7a36e0386002e',\n '07f67cc7d09c5f0588385d392faf3f614f4f26e1d9a4083250f6c1f3bc73193d',\n 'ceb395af34c5ea2be2badf519bf8f1e29658731c331fb14dd53cf79382fcdfae']"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "\n",
    "g = hashlib.sha256()\n",
    "g.update(bytes(block_1,\"utf-8\"))\n",
    "first_block = g.hexdigest()\n",
    "\n",
    "blocks = [block_2,block_3]\n",
    "blockchain = [first_block]\n",
    "\n",
    "\n",
    "for block in blocks:\n",
    "    h = hashlib.sha256()\n",
    "    h.update(bytes(blockchain[-1],\"utf-8\") + bytes(block,\"utf-8\"))\n",
    "    block_hash = h.hexdigest()\n",
    "    blockchain.append(block_hash)\n",
    "blockchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these outputs comes from chaining the successive blocks together. The power of this technique is that it makes it cryptographically (and statistically) nearly impossible to make any changes to the historical ledger without also recalculating the hashes for _every single operation that took place after that_ as well. THAT'S A LOT OF WORK. \n",
    "\n",
    "Finally, as an example to clarify, here is an example of the second block's hash without the chaining. Notice that it does not match the second hash in the sequence of hashes in the blockchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'6c577b126af66b5593c796e60e0b19e7fc526c0702a3b563d3b6d6b1e3ce1043'"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "p = hashlib.sha256()\n",
    "p.update(bytes(block_2,\"utf-8\"))\n",
    "p.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}